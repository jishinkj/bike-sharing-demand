{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how the modeling must be done once the EDA part is completed. I always separate the EDA code from the modeling code. \n",
    "\n",
    "\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. Save the target variable and concatenate both the train and test sets. To do this, we must drop `casual` and `registered`. Call the new dataframe as `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['count']\n",
    "datetime_col = test['datetime']\n",
    "\n",
    "train.drop(['casual', 'registered'],axis = 1, inplace = True)\n",
    "data = pd.concat([train.iloc[:,:-1],test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the `datetime` column, create additonal columns - `date`, `hour`, `year`, `weekday`, `month'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"] = data.datetime.apply(lambda x : str(x).split()[0])\n",
    "data[\"hour\"] = data.datetime.apply(lambda x : (str(x).split()[1]).split(\":\")[0]).astype(\"int\")\n",
    "data[\"year\"] = data.datetime.apply(lambda x : str(x).split()[0].split(\"-\")[0])\n",
    "data[\"weekday\"] = data.date.apply(lambda dateString : datetime.strptime(dateString,\"%Y-%m-%d\").weekday())\n",
    "data[\"month\"] = data.date.apply(lambda dateString : datetime.strptime(dateString,\"%Y-%m-%d\").month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Coercing To Category Type\n",
    "\n",
    "    - We must convert the type of categorical columns to character type so that the model doesn't consider them as numbers. The 1, 2, 3 and 4 in the `season` column are categories - season 4 shouldn't have a higher value than season 1, numerically. Once we convert them to charcters, 4 and 1 are considered as equals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalFeatureNames = [\"season\", \"holiday\", \"workingday\", \"weather\", \"weekday\", \"month\", \"year\", \"hour\"]\n",
    "numericalFeatureNames = [\"temp\",\"humidity\",\"windspeed\"]\n",
    "\n",
    "for var in categoricalFeatureNames:\n",
    "    data[var] = data[var].astype(\"category\")\n",
    "\n",
    "data = pd.get_dummies(data, columns = [\"season\",\"weather\",\"weekday\",\"month\",\"year\",\"hour\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropFeatures = [\"datetime\",\"atemp\",\"windspeed\",\"date\"]\n",
    "data.drop(dropFeatures,axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Separate the data back into train and test sets and find the log of the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:len(train['count']),:]\n",
    "test_df = data.iloc[len(train['count']):,:]\n",
    "\n",
    "y = np.log1p(y)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Split the train test in 80-20 partition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Regression model\n",
    "\n",
    "Here, I have decided to fit a Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X = X_train, y = y_train)\n",
    "y_pred = rfr.predict(X = X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "print(\"MAE is \",mean_absolute_error(np.exp(y_test), np.exp(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on the test set\n",
    "\n",
    "Run the predict method on the test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission = rfr.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV\n",
    "\n",
    "We must also take the exponent of the perdicted values as we had trained on the log of the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"datetime\": datetime_col, \"count\": np.expm1(y_pred_submission)})\n",
    "submission.to_csv('submissions/rfr_default_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook results in a score of 0.427 which is the Top 18% rank-wise. \n",
    "\n",
    "Hope this notebook was useful! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
